<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="AmakihiDistanceSampling_2018_Key_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="AmakihiDistanceSampling_2018_Key_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="AmakihiDistanceSampling_2018_Key_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="AmakihiDistanceSampling_2018_Key_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="AmakihiDistanceSampling_2018_Key_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="AmakihiDistanceSampling_2018_Key_files/navigation-1.1/tabsets.js"></script>
<link href="AmakihiDistanceSampling_2018_Key_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="AmakihiDistanceSampling_2018_Key_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">




</div>


<head>
<link rel="stylesheet" href="N:/Capacity Building and Academic Programs/SI-Mason Grad & Prof Training/Individual Courses--Folders/Bird Migration/2018/Materials/Distance/Exercises"> <link rel="stylesheet" type="text/css" href="styles.css">
</head>
<div id="amakihi-distance-sampling-exercise---answer-key" class="section level1">
<h1>Amakihi Distance Sampling Exercise - Answer Key</h1>
<p>
<i>Joe Kolowski, Ph.D.</i>
</p>
<div id="project-description-and-context" class="section level2">
<h2>Project Description and Context</h2>
<p><img style="float:right" src="images/amakihiPic.png" /></p>
<p>In this module, you will import point transect data on individual Amakihi (<em>Hemignathus virens</em>), a common type of honeycreeper in Hawaii. These data were collected as part of a larger translocation experiment, where data was collected on a suite of bird species (Fancy et al. 1997). Point transect surveys were performed at seven survey periods between July 1992 and April 1995. There were 41 point-count stations, though they were not all surveyed in some survey periods. We’ll be using this as an example where the use of covariates is appropriate. There are 3 potential covariates available in this case study: Observer ID (OBs), and time in minutes (MAS) and hours (HAS) after sunrise for observations. The goal of the project is to calculate the most unbiased and precise estimate of density of this species within each study period. The study is used as an illustrative example in Marques et al. (2007), and this is one of the Sample Projects provided with the program DISTANCE.</p>
</div>
<div id="exercise-objectives" class="section level2">
<h2>Exercise Objectives</h2>
<ul>
<li>Continue to practice with importing and exploring data for distance sampling analysis</li>
<li>Continue to practice with the use of covariates in analyzing distance sampling data</li>
<li>Assess which combination of covariates is most supported in modelling the detection process in this study</li>
<li>Independently complete a full analysis work flow, including model selection and results interpretation, to determine an unbiased density of Amakihi</li>
<li>If you have time, explore survey period to see if each survey period should be analysed independently to better assess overall density of Amakihi</li>
</ul>
<div id="librariessetup" class="section level3">
<h3>Libraries/Setup</h3>
<pre class="r"><code>library(Distance)</code></pre>
</div>
<div id="data-import-and-exploration" class="section level3">
<h3>Data Import and Exploration</h3>
<p>STEP1: Let’s first bring in the data, which exists as a .csv file called “amakihi.csv”</p>
<pre class="r"><code>library(Distance)
amakihiData &lt;- read.csv(&quot;https://www.dropbox.com/s/9b4mgh36p7p1ynx/amakihi.csv?dl=1&quot;)</code></pre>
<p>
STEP2: As always, you should begin by exploring the raw data. Use functions to view the data, look at its structure, and summarize the data.
<p>
<strong>Q1. What is the maximum distance at which a bird was observed?</strong>
<p>
<p>A1. With the <code>summary</code> function we can see the maximum distance observation was at 250 meters. We could also use <code>max(amakihiData$distance)</code>.</p>
<pre class="r"><code>head(amakihiData)</code></pre>
<pre><code>##   Study.Area Region.Label Area Sample.Label Effort distance OBS MAS HAS
## 1       Kana       Jul-92    0            1      1       40 TJS  50   1
## 2       Kana       Jul-92    0            1      1       60 TJS  50   1
## 3       Kana       Jul-92    0            1      1       45 TJS  50   1
## 4       Kana       Jul-92    0            1      1      100 TJS  50   1
## 5       Kana       Jul-92    0            1      1      125 TJS  50   1
## 6       Kana       Jul-92    0            1      1      120 TJS  50   1</code></pre>
<pre class="r"><code>str(amakihiData)</code></pre>
<pre><code>## &#39;data.frame&#39;:    1487 obs. of  9 variables:
##  $ Study.Area  : Factor w/ 1 level &quot;Kana&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Region.Label: Factor w/ 7 levels &quot;Apr-93&quot;,&quot;Apr-94&quot;,..: 6 6 6 6 6 6 6 6 6 6 ...
##  $ Area        : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ Sample.Label: int  1 1 1 1 1 1 1 1 2 2 ...
##  $ Effort      : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ distance    : int  40 60 45 100 125 120 140 80 65 90 ...
##  $ OBS         : Factor w/ 4 levels &quot;&quot;,&quot;SGF&quot;,&quot;TJS&quot;,..: 3 3 3 3 3 3 3 3 3 3 ...
##  $ MAS         : int  50 50 50 50 50 50 50 50 64 64 ...
##  $ HAS         : int  1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<pre class="r"><code>summary(amakihiData)</code></pre>
<pre><code>##  Study.Area  Region.Label      Area    Sample.Label      Effort 
##  Kana:1487   Apr-93:274   Min.   :0   Min.   : 1.0   Min.   :1  
##              Apr-94:148   1st Qu.:0   1st Qu.: 9.0   1st Qu.:1  
##              Apr-95:250   Median :0   Median :19.0   Median :1  
##              Dec-92:160   Mean   :0   Mean   :19.6   Mean   :1  
##              Jan-94:262   3rd Qu.:0   3rd Qu.:29.5   3rd Qu.:1  
##              Jul-92:183   Max.   :0   Max.   :41.0   Max.   :1  
##              Jul-93:210                                         
##     distance       OBS            MAS             HAS       
##  Min.   :  1.00      :   2   Min.   :-18.0   Min.   :0.000  
##  1st Qu.: 27.00   SGF: 229   1st Qu.: 78.0   1st Qu.:1.000  
##  Median : 45.00   TJS:1183   Median :137.0   Median :2.000  
##  Mean   : 50.67   TKP:  73   Mean   :140.9   Mean   :2.344  
##  3rd Qu.: 70.00              3rd Qu.:199.0   3rd Qu.:3.000  
##  Max.   :250.00              Max.   :307.0   Max.   :5.000  
##  NA&#39;s   :2                   NA&#39;s   :2       NA&#39;s   :2</code></pre>
<p>Note that our observer covariate is already recognized as a factor in R, which is what we want. Hours after sunrise could be treated either as a factor, if we want each hour to exist as an independent sample, or we could leave it as is, and its relationship with distance will be assessed in a linear fashion (i.e. detection function parameters will consistently increase or decrease with hour after sunrise).</p>
<p>
STEP3: Plot the distance data as a histogram, trying a range of different bin sizes to explore the raw data.
<p>
<p><strong>Q2. Do you see any potential problems or issues with the data? If so what are they?</strong></p>
<pre class="r"><code>hist(
  amakihiData$distance,
  breaks = seq(0, 260),
  main = &quot;&quot;,
  xlab = &quot;Distance&quot;
)</code></pre>
<p><img src="AmakihiDistanceSampling_2018_Key_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>
A2. There are a few things to consider when looking at our raw data. First, there are a series of long-distance observations which will be challenging to fit to a detection function, and which aren’t important to the analysis. They should be truncated. Second, while there is a clear decline in observation frequency after 50m, there is a series of observations at further distances which extend the potential peak in the data. This could be the result of differences across observers, or time periods. Third, there do appear to be rounding errors at certain distances, but there is not much we can do to address this.
<p>
STEP4: Looking at the data with different bin sizes, decide on a reasonable truncation distance or %.
<p>
<p><strong>Q3. What did you decide and why?</strong></p>
<p>
<p>A3. One could decide to truncate the furthest 10% of observations, or we could look at the data and select a distance which removes the bulk of these sporadic far observations. The case study in the Marques paper truncates at 82.5 meters, so that is what I’ll proceed with here, but this is not necessarily the only solution. We can look at the data with a few bin sizes, using our new truncation level. We can still see an issue with a second peak in observation frequencies, but perhaps our covariates will help to account for this.</p>
<pre class="r"><code>par(mfrow=c(1,2))
hist(
  amakihiData$distance[amakihiData$distance &lt; 82.5],
  breaks = 33,
  main = &quot;&quot;,
  xlab = &quot;Distance&quot;
)
hist(
  amakihiData$distance[amakihiData$distance &lt; 82.5],
  breaks = 10,
  main = &quot;&quot;,
  xlab = &quot;Distance&quot;
)</code></pre>
<p><img src="AmakihiDistanceSampling_2018_Key_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>
Let’s now look at our 3 covariates to see how they relate to observed distances. Boxplots are best in this case for factor covariates, regular scatterplots for continuous variables.
<p>
STEP5: Create boxplots or scatterplots of our 3 covariates, with distance on the y axes, to look at how these covariates may influence the detection function.
<p>
<strong>Q4: Which observer tends to observe birds at the longer distances?</strong>
<p>
A4: TJS
<p>
<strong>Q5: Do observation distances tend to increase or decrease as time after sunrise increases?</strong>
<p>
<p>A5: As you go further from sunrise, average observation distance tends to decline.</p>
<pre class="r"><code>par(mfrow=c(1,3))
boxplot(amakihiData$distance ~ amakihiData$OBS,
        xlab = &quot;Observer&quot;,
        ylab = &quot;Distance(m)&quot;)

plot(
  amakihiData$MAS,
  amakihiData$distance,
  xlab = &quot;Minutes after sunrise&quot;,
  ylab = &quot;Distance(m)&quot;,
  pch = 19,
  cex = 0.6
  )

abline(reg = lm(amakihiData$distance ~ amakihiData$MAS),
       lwd = 2)

boxplot(amakihiData$distance ~ amakihiData$HAS,
        xlab = &quot;Hour&quot;,
        ylab = &quot;Distance(m)&quot;)</code></pre>
<p><img src="AmakihiDistanceSampling_2018_Key_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Note that we are entertaining three possible covariates in our detection function: observer, hours and minutes since sunrise. Observer and hours are variables that take on values between 1 and 3 in the case of observer, and 1 to 6 in the case of hours. However minutes can take on values from -9 (detections before sunrise) to &gt;300. The disparity in scales of measure between MAS and the other candidate covariates can lead to difficulties in the performance of the optimiser fitting the detection functions in R. The solution to the difficulty is to scale MAS such that it is on a scale (~1 to 5) comparable with the other covariates.</p>
<p>
<p>Dividing all the MAS measurements by the standard deviation of those measurements accomplishes the desired compaction of the range of the MAS covariate without changing the shape of the distribution of MAS values. Execute the following code to do this.</p>
<pre class="r"><code>amakihiData$MAS &lt;- amakihiData$MAS / sd(amakihiData$MAS, na.rm = TRUE)</code></pre>
</div>
<div id="basic-conventional-distance-sampling-analysis-of-amakihi-data---no-covariates" class="section level3">
<h3>Basic Conventional Distance Sampling Analysis of Amakihi Data - no covariates</h3>
<p>
It’s always good practice to begin with a basic analysis of your data as a starting point, even if we know we want to explore various covariates.
<p>
STEP6: Using your selected truncation amount, run the 4 common detection function models on this data set, with no covariates. These include: Half-normal cosine, Half-normal hermite, Hazard-rate simply polynomial, and Uniform cosine. Compare the AIC values of these 4 models.
<p>
<p><em>Remember that you need to think about conversion units here. We want our output to be in hectares (100m by 100m) but our distance units are in meters. Be sure to select an appropriate value for the <code>convert.units</code> argument.</em></p>
<pre class="r"><code>amakihi.hn.herm &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hn&quot;,
  adjustment = &quot;herm&quot;,
  convert.units = .01
  )
AIC(amakihi.hn.herm)</code></pre>
<pre><code>## &#39;log Lik.&#39; 10804.51 (df=3)</code></pre>
<pre class="r"><code>amakihi.hn.cos &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hn&quot;,
  adjustment = &quot;cos&quot;,
  convert.units = .01
  )
AIC(amakihi.hn.cos)</code></pre>
<pre><code>## &#39;log Lik.&#39; 10799.1 (df=5)</code></pre>
<pre class="r"><code>amakihi.uni.cos &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;unif&quot;,
  adjustment = &quot;cos&quot;,
  convert.units = .01
  )
AIC(amakihi.uni.cos)</code></pre>
<pre><code>## &#39;log Lik.&#39; 10802.77 (df=2)</code></pre>
<pre class="r"><code>amakihi.haz.simp &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hr&quot;,
  adjustment = &quot;poly&quot;,
  convert.units = .01
  )
AIC(amakihi.haz.simp)</code></pre>
<pre><code>## &#39;log Lik.&#39; 10807.55 (df=2)</code></pre>
<pre class="r"><code>summary1 &lt;-
  summarize_ds_models(amakihi.haz.simp,
  amakihi.uni.cos,
  amakihi.hn.cos,
  amakihi.hn.herm,
  output = &quot;plain&quot;)</code></pre>
<pre class="r"><code>library(knitr)</code></pre>
<pre class="r"><code>kable(summary1, format = &quot;markdown&quot;)</code></pre>
<table style="width:100%;">
<colgroup>
<col width="2%" />
<col width="10%" />
<col width="38%" />
<col width="5%" />
<col width="9%" />
<col width="13%" />
<col width="15%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Model</th>
<th align="left">Key function</th>
<th align="left">Formula</th>
<th align="right">C-vM <span class="math inline">\(p\)</span>-value</th>
<th align="right">Average detectability</th>
<th align="right">se(Average detectability)</th>
<th align="right">Delta AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">3</td>
<td align="left">amakihi.hn.cos</td>
<td align="left">Half-normal with cosine adjustment terms of order 2,3,4,5</td>
<td align="left">~1</td>
<td align="right">0.5573050</td>
<td align="right">0.2816680</td>
<td align="right">0.0374515</td>
<td align="right">0.000000</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">amakihi.uni.cos</td>
<td align="left">Uniform with cosine adjustment terms of order 1,2</td>
<td align="left">NA</td>
<td align="right">0.4395449</td>
<td align="right">0.2883563</td>
<td align="right">0.0130070</td>
<td align="right">3.668929</td>
</tr>
<tr class="odd">
<td align="left">4</td>
<td align="left">amakihi.hn.herm</td>
<td align="left">Half-normal with Hermite polynomial adjustment terms of order 4,6</td>
<td align="left">~1</td>
<td align="right">0.4389345</td>
<td align="right">0.2878194</td>
<td align="right">0.0168241</td>
<td align="right">5.404129</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">amakihi.haz.simp</td>
<td align="left">Hazard-rate</td>
<td align="left">~1</td>
<td align="right">0.3344042</td>
<td align="right">0.3285785</td>
<td align="right">0.0201310</td>
<td align="right">8.447904</td>
</tr>
</tbody>
</table>
<p>
<strong>Q6: Based on AIC values, which of these 4 models best fits the data?</strong>
<p>
A6: Based on AIC values the half-normal cosine model with an AIC value of 10799.1 fits the data best.
<p>
STEP7: Look at the summary results of your best model. Then plot the results of the best model to look at the fit of the detection function.
<p>
<p><strong>Q7: Do you see any issues with the detection function?</strong></p>
<pre class="r"><code>summary(amakihi.hn.cos)</code></pre>
<pre><code>## 
## Summary for distance analysis 
## Number of observations :  1243 
## Distance range         :  0  -  82.5 
## 
## Model : Half-normal key function with cosine adjustment terms of order 2,3,4,5 
## 
## Strict monotonicity constraints were enforced.
## AIC   : 10799.1 
## 
## Detection function parameters
## Scale coefficient(s):  
##             estimate         se
## (Intercept) 3.567027 0.02196772
## 
## Adjustment term coefficient(s):  
##                 estimate         se
## cos, order 2  0.22318565 0.05009085
## cos, order 3 -0.15644024 0.04238818
## cos, order 4  0.13645497 0.04225339
## cos, order 5 -0.05150864 0.04007986
## 
##                        Estimate           SE        CV
## Average p              0.281668   0.03745147 0.1329632
## N in covered region 4412.996953 596.27915804 0.1351189
## 
## Summary statistics:
##   Region      Area CoveredArea Effort    n   k       ER     se.ER
## 1 Apr-93  87.66811    87.66811     41  231  41 5.634146 0.3289972
## 2 Apr-94  87.66811    51.31792     24  141  24 5.875000 0.2712859
## 3 Apr-95  87.66811    85.52986     40  212  40 5.300000 0.4938078
## 4 Dec-92  87.66811    85.52986     40  140  40 3.500000 0.3121472
## 5 Jan-94  87.66811    87.66811     41  172  41 4.195122 0.3088521
## 6 Jul-92  87.66811    87.66811     41  146  41 3.560976 0.1945877
## 7 Jul-93  87.66811    85.52986     40  201  40 5.025000 0.2984737
## 8  Total 613.67675   570.91182    267 1243 267 4.655431 0.1361385
##        cv.ER
## 1 0.05839344
## 2 0.04617632
## 3 0.09317129
## 4 0.08918492
## 5 0.07362173
## 6 0.05464449
## 7 0.05939775
## 8 0.02924294
## 
## Density:
##    Label Estimate        se        cv      lcl       ucl        df
## 1 Apr-93 9.354764 1.3585038 0.1452205 7.045037 12.421740  818.8505
## 2 Apr-94 9.754670 1.3730009 0.1407532 7.410110 12.841050  871.9354
## 3 Apr-95 8.799958 1.4287429 0.1623579 6.407001 12.086663  318.0522
## 4 Dec-92 5.811293 0.9304088 0.1601036 4.249957  7.946228  350.4958
## 5 Jan-94 6.965452 1.0586426 0.1519848 5.176413  9.372808  540.6522
## 6 Jul-92 5.912535 0.8499509 0.1437540 4.465509  7.828462  898.3467
## 7 Jul-93 8.343356 1.2150201 0.1456273 6.278305 11.087641  786.7813
## 8  Total 7.848861 1.0635138 0.1354991 6.024051 10.226444 1323.1052</code></pre>
<pre class="r"><code>plot(amakihi.hn.cos, main = &quot;Amakihi data pooled, \nhalf-normal cosine detection function&quot;,
     pdf = T)</code></pre>
<img src="AmakihiDistanceSampling_2018_Key_files/figure-html/unnamed-chunk-11-1.png" width="672" />
<p>
<p>A7: You can see from the output of the model run that the half-normal cosine has 4 adjustment parameters and a total of 5 parameters. This is a very complex detection function, primarily because it is attempting to account for the second peak in observations, where a standard/appropriate function should be monotonically decreasing. Hopefully our covariates will help address this.</p>
</div>
<div id="multiple-covariate-distance-sampling-mcds-of-amakihi-data" class="section level3">
<h3>Multiple Covariate Distance Sampling (MCDS) of Amakihi Data</h3>
<p>
Let’s try now to incorporate our 3 covariates into our modeling. We cannot assume that our best model from above will continue to be the best detection function, so we need to investigate not only different combinations of our covariates, but also different key functions. In R, due to it’s optimization engine, models with covariates and adjustment terms do not converge. Thus, the package prevents us from using adjustment terms. This simplifies things here, but is a disadvantage of running these models in R vs. the Windows program DISTANCE.
<p>
<p>In any case, let’s first convert HAS to a factor covariate, since the graph of this variable indicates the trend in detection frequencies may not be linear as hours proceed from sunrise.</p>
<pre class="r"><code>amakihiData$HAS &lt;- as.factor(amakihiData$HAS)</code></pre>
<p>
STEP8: Test the following models. Combining them with the 4 models we’ve run above for a total of 14 models, compare them with AIC, as well as the Cramer von-Mises test (using the <code>summarize_ds_models</code> function).
<p>
<ul>
<li>OBS (Half-normal)</li>
<li>OBS (Hazard rate)</li>
<li>MAS (Half-normal)</li>
<li>MAS (Hazard rate)</li>
<li>HAS (Half-normal)</li>
<li>HAS (Hazard rate)</li>
<li>OBS + MAS (Half-normal)</li>
<li>OBS + MAS (Hazard rate)</li>
<li>OBS + HAS (Half-normal)</li>
<li>OBS + HAS (Hazard rate)</li>
</ul>
<pre class="r"><code>amakihi.hn.obs &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hn&quot;,
  formula = ~ OBS,
  convert.units = .01
  )

amakihi.hr.obs &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hr&quot;,
  formula = ~ OBS,
  convert.units = .01
  )

amakihi.hn.MAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hn&quot;,
  formula = ~ MAS,
  convert.units = .01
  )

amakihi.hr.MAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hr&quot;,
  formula = ~ MAS,
  convert.units = .01
  )

amakihi.hn.HAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hn&quot;,
  formula = ~ HAS,
  convert.units = .01
  )

amakihi.hr.HAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hr&quot;,
  formula = ~ HAS,
  convert.units = .01
  )

amakihi.hn.obs_HAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hn&quot;,
  formula = ~ OBS + HAS,
  convert.units = .01
  )

amakihi.hr.obs_HAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hr&quot;,
  formula = ~ OBS + HAS,
  convert.units = .01
  )

amakihi.hn.obs_MAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hn&quot;,
  formula = ~ OBS + MAS,
  convert.units = .01
  )

amakihi.hr.obs_MAS &lt;- ds(
  amakihiData,
  truncation = 82.5,
  transect = &quot;point&quot;,
  key = &quot;hr&quot;,
  formula = ~ OBS + MAS,
  convert.units = .01
  )

summary2 &lt;-
  summarize_ds_models(
  amakihi.hn.herm,
  amakihi.haz.simp,
  amakihi.hn.cos,
  amakihi.uni.cos,
  amakihi.hn.obs,
  amakihi.hr.obs,
  amakihi.hn.MAS,
  amakihi.hr.MAS,
  amakihi.hn.HAS,
  amakihi.hr.HAS,
  amakihi.hn.obs_HAS,
  amakihi.hr.obs_HAS,
  amakihi.hn.obs_MAS,
  amakihi.hr.obs_MAS,
  output = &quot;plain&quot;
  )

kable(summary2, format = &quot;markdown&quot;)</code></pre>
<table>
<colgroup>
<col width="2%" />
<col width="11%" />
<col width="37%" />
<col width="6%" />
<col width="8%" />
<col width="12%" />
<col width="15%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Model</th>
<th align="left">Key function</th>
<th align="left">Formula</th>
<th align="right">C-vM <span class="math inline">\(p\)</span>-value</th>
<th align="right">Average detectability</th>
<th align="right">se(Average detectability)</th>
<th align="right">Delta AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">14</td>
<td align="left">amakihi.hr.obs_MAS</td>
<td align="left">Hazard-rate</td>
<td align="left">~OBS + MAS</td>
<td align="right">0.3890855</td>
<td align="right">0.3186670</td>
<td align="right">0.0201472</td>
<td align="right">0.000000</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">amakihi.hr.obs</td>
<td align="left">Hazard-rate</td>
<td align="left">~OBS</td>
<td align="right">0.2707237</td>
<td align="right">0.3142730</td>
<td align="right">0.0204413</td>
<td align="right">1.072908</td>
</tr>
<tr class="odd">
<td align="left">12</td>
<td align="left">amakihi.hr.obs_HAS</td>
<td align="left">Hazard-rate</td>
<td align="left">~OBS + HAS</td>
<td align="right">0.4502642</td>
<td align="right">0.3197341</td>
<td align="right">0.0200473</td>
<td align="right">5.759905</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">amakihi.hn.cos</td>
<td align="left">Half-normal with cosine adjustment terms of order 2,3,4,5</td>
<td align="left">~1</td>
<td align="right">0.5573050</td>
<td align="right">0.2816680</td>
<td align="right">0.0374515</td>
<td align="right">21.725549</td>
</tr>
<tr class="odd">
<td align="left">11</td>
<td align="left">amakihi.hn.obs_HAS</td>
<td align="left">Half-normal</td>
<td align="left">~OBS + HAS</td>
<td align="right">0.0112111</td>
<td align="right">0.3405084</td>
<td align="right">0.0112599</td>
<td align="right">23.705350</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">amakihi.uni.cos</td>
<td align="left">Uniform with cosine adjustment terms of order 1,2</td>
<td align="left">NA</td>
<td align="right">0.4395449</td>
<td align="right">0.2883563</td>
<td align="right">0.0130070</td>
<td align="right">25.394478</td>
</tr>
<tr class="odd">
<td align="left">13</td>
<td align="left">amakihi.hn.obs_MAS</td>
<td align="left">Half-normal</td>
<td align="left">~OBS + MAS</td>
<td align="right">0.0076156</td>
<td align="right">0.3429623</td>
<td align="right">0.0111657</td>
<td align="right">26.498966</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">amakihi.hn.herm</td>
<td align="left">Half-normal with Hermite polynomial adjustment terms of order 4,6</td>
<td align="left">~1</td>
<td align="right">0.4389345</td>
<td align="right">0.2878194</td>
<td align="right">0.0168241</td>
<td align="right">27.129677</td>
</tr>
<tr class="odd">
<td align="left">8</td>
<td align="left">amakihi.hr.MAS</td>
<td align="left">Hazard-rate</td>
<td align="left">~MAS</td>
<td align="right">0.5579939</td>
<td align="right">0.3335896</td>
<td align="right">0.0201104</td>
<td align="right">28.253419</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">amakihi.haz.simp</td>
<td align="left">Hazard-rate</td>
<td align="left">~1</td>
<td align="right">0.3344042</td>
<td align="right">0.3285785</td>
<td align="right">0.0201310</td>
<td align="right">30.173452</td>
</tr>
<tr class="odd">
<td align="left">10</td>
<td align="left">amakihi.hr.HAS</td>
<td align="left">Hazard-rate</td>
<td align="left">~HAS</td>
<td align="right">0.5802562</td>
<td align="right">0.3326671</td>
<td align="right">0.0200215</td>
<td align="right">30.843087</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="left">amakihi.hn.obs</td>
<td align="left">Half-normal</td>
<td align="left">~OBS</td>
<td align="right">0.0032978</td>
<td align="right">0.3462978</td>
<td align="right">0.0111582</td>
<td align="right">39.127963</td>
</tr>
<tr class="odd">
<td align="left">9</td>
<td align="left">amakihi.hn.HAS</td>
<td align="left">Half-normal</td>
<td align="left">~HAS</td>
<td align="right">0.0096201</td>
<td align="right">0.3472573</td>
<td align="right">0.0112909</td>
<td align="right">47.655397</td>
</tr>
<tr class="even">
<td align="left">7</td>
<td align="left">amakihi.hn.MAS</td>
<td align="left">Half-normal</td>
<td align="left">~MAS</td>
<td align="right">0.0072817</td>
<td align="right">0.3493128</td>
<td align="right">0.0112744</td>
<td align="right">49.161526</td>
</tr>
</tbody>
</table>
<p>
<strong>Q8: Which model is best and why?</strong>
<p>
A8: The model with both OBS and MAS is the best, with a hazard rate key function.
<p>
<p>STEP9:Review the summary results of your best model.</p>
<pre class="r"><code>summary(amakihi.hr.obs_MAS)</code></pre>
<pre><code>## 
## Summary for distance analysis 
## Number of observations :  1243 
## Distance range         :  0  -  82.5 
## 
## Model : Hazard-rate key function 
## AIC   : 10777.38 
## 
## Detection function parameters
## Scale coefficient(s):  
##                estimate         se
## (Intercept)  3.21660465 0.12115244
## OBSTJS       0.51887432 0.09630820
## OBSTKP       0.09831049 0.17503007
## MAS         -0.06595015 0.03655281
## 
## Shape coefficient(s):  
##             estimate         se
## (Intercept) 0.885308 0.06315655
## 
##                        Estimate           SE         CV
## Average p              0.318667   0.02014721 0.06322341
## N in covered region 3900.624101 263.72270841 0.06761039
## 
## Summary statistics:
##   Region      Area CoveredArea Effort    n   k       ER     se.ER
## 1 Apr-93  87.66811    87.66811     41  231  41 5.634146 0.3289972
## 2 Apr-94  87.66811    51.31792     24  141  24 5.875000 0.2712859
## 3 Apr-95  87.66811    85.52986     40  212  40 5.300000 0.4938078
## 4 Dec-92  87.66811    85.52986     40  140  40 3.500000 0.3121472
## 5 Jan-94  87.66811    87.66811     41  172  41 4.195122 0.3088521
## 6 Jul-92  87.66811    87.66811     41  146  41 3.560976 0.1945877
## 7 Jul-93  87.66811    85.52986     40  201  40 5.025000 0.2984737
## 8  Total 613.67675   570.91182    267 1243 267 4.655431 0.1361385
##        cv.ER
## 1 0.05839344
## 2 0.04617632
## 3 0.09317129
## 4 0.08918492
## 5 0.07362173
## 6 0.05464449
## 7 0.05939775
## 8 0.02924294
## 
## Density:
##    Label Estimate        se         cv      lcl       ucl        df
## 1 Apr-93 6.732402 0.5598067 0.08315111 5.714962  7.930978  172.1478
## 2 Apr-94 7.322282 0.6146889 0.08394772 6.206334  8.638887  180.9460
## 3 Apr-95 7.659762 0.7527262 0.09827018 6.307886  9.301365  115.3644
## 4 Dec-92 5.769796 0.7369173 0.12771981 4.486150  7.420740  130.8295
## 5 Jan-94 4.784721 0.4626799 0.09669944 3.952399  5.792320  114.5675
## 6 Jul-92 7.275317 1.0825287 0.14879471 5.439986  9.729849  522.2012
## 7 Jul-93 8.520228 1.0150497 0.11913410 6.739310 10.771767  156.8543
## 8  Total 6.866358 0.4650800 0.06773314 6.012980  7.840851 1448.8637</code></pre>
<p>
<strong>Q9: What is the final overall density estimate, per hectare, from your best model? Include the coefficient of variation, and the confidence interval.</strong>
<p>
A9: The density estimate from the best model is 6.87 birds per hectare with a coefficient of variation of 6.8%. The 95% CI stretches from 6.01 to 7.84. Note that this is a much smaller CV and confidence interval than we had from our basic model with no covariates.
<p>
<em>It should be noted here that the models fitted with the half-normal function are actually much better when fitted in the program DISTANCE. This is because the model optimization engines used in DISTANCE are better, and they were able to fit these models WITH adjustment terms. In the end, the hazard rate models, even without adjustment terms, were still better than the half-normal models in all cases, but if running these models in DISTANCE, the AIC values of the half-normal models would be much lower.</em>
<p>
<p>STEP10: Use the <code>ddf.gof</code> function to calculate various diagnostics for your best model. Using code from the demo, plot the QQplot and include the Cramer von-Mises test results on the plot</p>
<pre class="r"><code>amakihi.hr.obs_Mas.fit &lt;- ddf.gof(amakihi.hr.obs_MAS$ddf)
message &lt;-
  paste(
  &quot;Cramer von-Mises W=&quot;,
  round(amakihi.hr.obs_Mas.fit$dsgof$CvM$W, 3),
  &quot;\nP=&quot;,
  round(amakihi.hr.obs_Mas.fit$dsgof$CvM$p, 3)
  )
text(0.6, 0.1, message, cex = 0.8)</code></pre>
<p><img src="AmakihiDistanceSampling_2018_Key_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>
<strong>Q10: Do you see any reason to be cautious about our final model here, or do we have evidence that this is a reasonably good fit of the data?</strong>
<p>
A10: The QQ plot, and the lack of significance of the CvM test are both indicating that our model is a reasonable fit to the data.
<p>
<p>STEP11: Let’s graph our detection functions for each observer. Look in the help menu for the function <code>plot.ds</code> and figure out how to use the <code>subset</code> argument to graph the detection function for each of the three observers separately. Label the main titles with the names of the observers, and set their y axes to go from 0 to 1.5 so we can compare them easily. For some reason the <code>PDF =T</code> does not work in these graphs, so you can graph the standard detection functions here (that is, use the default graph).</p>
<pre class="r"><code>par(mfrow=c(1,3))
plot(
  amakihi.hr.obs_MAS,
  subset = OBS == &quot;TJS&quot;,
  nc = 15,
  ylim = c(0, 1.5),
  main = &quot;Observer TJS&quot;,
  showpoints = F
  )
plot(
  amakihi.hr.obs_MAS,
  subset = OBS == &quot;SGF&quot;,
  nc = 15,
  ylim = c(0, 1.5),
  main = &quot;Observer SGF&quot;,
  showpoints = F
  )
plot(
  amakihi.hr.obs_MAS,
  subset = OBS == &quot;TKP&quot;,
  nc = 15,
  ylim = c(0, 1.5),
  main = &quot;Observer TKP&quot;,
  showpoints = F
  )</code></pre>
<p><img src="AmakihiDistanceSampling_2018_Key_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
<div id="extra-practice---investigating-survey-periods-as-strata" class="section level3">
<h3>Extra Practice - Investigating Survey Periods as Strata</h3>
<p>Look again at the <code>summary</code> of your best model and focus on the encounter rate (ER) for each survey time period. Remember that we have 7 different survey periods during which field data was collected. You’ll see that the encounter rate varies quite a bit across these survey periods. In all the analyses above, we’ve created pooled detection functions across all these survey periods, assuming that detection processes were more or less similar across these periods. But this may not be the case. For example encounter rates in December 1992 and July 1992 were substantially lower than during other periods. Using the demo exercise (House Wren) as a guide, where survey blocks were analyzed as separate strata, analyze the Amakihi data again, this time keeping each survey period as a separate strata. For simplicity, try only the half-normal cosine, and the hazard rate simple polynomial models for each survey period. In the end, sum the AIC values of your final 7 models (one for each survey period) and compare with the AIC value of our initial model above which pooled these survey periods (half-normal cosine, no covariates) to see if it is worth estimating separate detection functions for each survey period. Think about how you might go about calculating a final global density estimate when each survey period is analyzed separately like this.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
