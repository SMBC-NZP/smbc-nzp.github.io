---
output:
 html_document:
  theme: yeti
---

<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<style>

code{
  background-color:#f2f2f2;
  border-radius: 25px;
}
 
span.co{
  color:#000080;
  font-weight: bold;
}
 
img{
  display: block;
  padding-left: 15px;
  padding-right: 15px;
  padding-top: 10px;
  padding-bottom: 10px;
}

p{
  text-align: left;
  font-size: 18px;
}

ul, ol{
  line-height: 27px;
  text-align: left;
  font-size: 18px;
  margin-left: 0px;
}
 
blockquote{
  font-size: 18px;
  border-left: 8px solid #292093;
  background-color: #e6ffff;
  padding-left: 16px;
  padding-right: 16px;
}
 
.row{
  margin: auto;
}
 
table {
  border-collapse: collapse;
}

table, td, th {
  border: 1px solid black;
  padding: 5px;
  text-align: center;
  vertical-align: middle;
}
 
 /* Create two equal columns that floats next to each other */
.column {
  float: left;
  width: 50%;
  padding: 10px;
}

/* Clear floats after the columns */
.row:after {
  content: "";
  display: table;
  clear: both;
}

.roundBorder {
  border-radius: 25px;
  border: 5px solid #30288C;
  background: #D6EAF8;
  padding-left: 20px;
  padding-right: 20px;
  padding-top: 10px;
  padding-bottom: 10px;
}

.roundBorderBlack {
  border-radius: 25px;
  border: 10px solid #D3D3D3;
  padding-left: 20px;
  padding-right: 20px;
  padding-top: 10px;
  padding-bottom: 10px;
}

.roundBorderBlackEx {
  border-radius: 5px;
  border: 5px solid #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  padding-top: 2px;
}

.roundBorderEx {
  border-radius: 3px;
  border: 5px solid #30288C;
  background: #D6EAF8;
  padding-left: 5px;
  padding-right: 5px;
  padding-top: 2px;
}

.tt {
    position: relative;
    display: inline-block;
    class: inline; 
    font-weight: bold;
    font-family: "Avenir";
    font-size: 18px;
    border-bottom: 1px black;
}

/* Tooltip text */
.tt .ttText {
    visibility: hidden;
    font-weight: normal;
    font-size: 18px;
    width: 200px;
    background-color: black;
    border: 1px solid black;
    color: white;
    text-align: left;
    padding: 5px;
    border-radius: 6px;
    position: absolute;
    z-index: 1;
}

/* Show the tooltip text when you mouse over the tooltip container */
.tt:hover .ttText {
    visibility: visible;
}

</style>

```{r, eval = TRUE, include  = FALSE}
# Load RCurl library:

library(RCurl)

# Load a source script:

script <-
  getURL(
    "https://raw.githubusercontent.com/bsevansunc/workshop_languageOfR/master/sourceCode.R"
  )

# Evaluate then remove the source script:

eval(parse(text = script))

rm(script)

library(knitr) ; library(kableExtra)

options(knitr.table.format = "html")
```

<h1 style="text-align: center;">Introduction to data science in R, Lesson 3:<br/>Writing functions</h1>
<br>
<!img style="float: left; margin: 0px 0px 15px 15px;" src="nzpLogo.jpg" width="150" />
<p style = "text-align: center; font-size: 14px;">Brian S. Evans, Ph.D.<br />
Migratory Bird Center<br/>
Smithsonian Conservation Biology Institute</p>
<hr>

<h2>Introduction</h2>
<br>
<p>It is estimated that the process of preparing data for analysis, <b>data manipulation</b> or, as it is often called, <b>data wrangling</b>, consumes up to 80 percent of total analysis time (Dasu and Johnson 2003).
<img style="PADDING-RIGHT:20px; PADDING-TOP: 10px; PADDING-BOTTOM: 10px; padding-left: 0px" align = "left" src="http://images.nationalgeographic.com/wpf/media-live/photos/000/183/cache/upside-down-bird_18378_990x742.jpg" height="400px" width = "400px" title=" Hideta Nagai, National Geographic"/>
In classes on statistics and applied data analysis, emphasis is generally placed on the analysis of data and, historically, comparatively little attention is paid to how to prepare one's data to be analyzed. With increasing calls for reproducibility, however, this is beginning to change. Increasingly, journals are asking authors to publish both data and R code as supplemental information for their manuscripts. This helps advance scientific knowledge, as researchers do not have to reinvent the wheel every time they conduct a similar analysis, and ensures replicability, as interested parties (e.g., reviewers) can repeat your every step in your data analysis with the exception of the collection of field data! Considering this, it is in all of our best interest that data manipulation be simple, that our scripts are legible and easy-to-follow, and that we can avoid "script bloat" by using methods (such as functions and occasionally <i>for loops</i>!) to reduce the length of our scripts. It is highly recommended that you take a "cradle-to-grave" approach to data manipulation and analysis:</p>
<br>
<ol>
<li>Collect and store your data in well-constructed spreadsheets and <b>databases</b>.</li>
<li>DO NOT complete ANY step in the data manipulation process in Excel! Doing so makes it difficult for others to truly replicate your analyses.</li>
<li>Basic formatting steps to prepare your data for analysis, <b>data tidying</b>, should be completed prior to any summarizing, further cleaning, or analysis of data.</li>
<li>Clean data, including removing "bad" records, such as NA values (i.e., "Not Available") and extreme outliers, prior to (not during) analysis.</li>
<li>Group and summarize data as a final step the final data exploration and formatting processes -- prior to more complex statistical analyses.</li>
</ol>
<br>
<i>Note: This lesson borrows <b>heavily</b> from Hadley Wickham's awesome paper on Tidy Data (2014). We strongly recommend this paper to all R users!</i>
    
<hr>
<h2>Before you begin</h2>
<p>Copy-paste-and run the following code in R Studio to load the packages and read in the data we will be using for this lesson:</p>
<br>

```{r, eval=FALSE}
# Load RCurl library:

library(RCurl)

# Load a source script:

script <-
  getURL(
    "https://raw.githubusercontent.com/bsevansunc/workshop_languageOfR/master/sourceCode.R"
  )

# Evaluate then remove the source script:

eval(parse(text = script))

rm(script)
```

<hr>

<h2>The rule for tidy data</h2>
<br>
<p>At the core of the <b>Tidyverse</b> is the notion of tidy data. Tidy data are easy to modify, summarize, model, and communicate to others. At each step in our data science process, we should be thinking about the structure of our data and taking every step we can to ensure that they are tidy.</p>

<p>In the <b>Tidyverse</b>, a tidy dataset has three qualities:</p>
<ol>
<li>Each variable forms a column</li>
<li>Each observation forms a row</li>
<li>Each level of observation forms a table</li>
</ol>

<p>These qualities are a re-wording of the three normalization rules of database design (Codd) that form the backbone of much of the field of data science. These rules are:</p>

<ol>
<li><b>First normal</b>:
<ul>
<li>All rows represent a unique record (primary key)</li>
<li>All values are atomic</li>
<li>Columns do not contain repeated grouping</li>
</ul>
</li>
<li><b>Second normal</b>: All columns are unique to the primary key (observation)</li>
<li><b>Third normal</b>: All columns are non-transitively dependent.
<ul><li>Column values are <b>only</b> directly dependent on the column that defines the observation</ul></li>
</li>
</ol>
<hr>

<h2>Fixing violations of the rules for tidy data</h2>

<h3>Wide to long and long to wide</h3>

<p>Below is a typical example in which  the influence of a treatment was measured on three test subjects and the results were stored as:</p>

```{r, eval = T}
untidyFrame
```

<p>Tidy? Nope. In this case, each subject has its own row, not each observation. This is a violation of the second rule of tidy data (each observation forms a row). We would have to do some awkward wrangling in base R to get this into a tidy format. Luckily, Hadley Wickham and his team created the `tidyr` package in R with the specific aim of turning messy datasets into tidy ones.</p>

<p>With the `tidyr` function `gather`, we collapse multiple columns into "key-value pairs". In the above example, we are interested in the treatment "values" for each of our "key" values. To do so, we provide:</p>

<ol>
<li>The data frame ("untidyFrame") we will be reshaping</li>
<li>The name of the new "key" field for which we are gathering the data ("treatment")</li>
<li>The name of the new "value" field where the values for that field will be stored</li>
<li>The columns for which the values will be restructured (these may be referred to by name or column number)</li>
</ol>

```{r, eval = T, echo=TRUE}
gather(
  data = untidyFrame,
  key = treatment,
  value = value,
  treatmentA:treatmentB
  )
```

<p>Let's give a more bird-y example. I collected bird point count data from sites in Washington, D.C. For each bird, I calculated the distance between myself and the observed birds, in units of 10 meters. On my datasheet I recorded the following:</p>
<br>
<div class = "row">
```{r, eval = T, echo=F, warning=FALSE}
kable(wideFrame, "html") %>%
  kable_styling(
  bootstrap_options = c("striped", "hover"),
  full_width = FALSE,
  font_size = 16,
  position = "float_left"
  )
```
</div>

<p>In the above, each observation is of a given species at a given distance class. The grouping of the distance columns is a clear sign that these data are not in tidy format. In the language of the tidyverse, I have split one variable (the count of birds) into multiple columns. As such, we are compelled to tidy our data by collapsing the distances into a single column. In the script below we use the `tidyr` function `gather` as:

```{r, eval = TRUE, echo=TRUE}
tidyCounts <- gather(data = wideFrame, 
  key = distance,
  value = obs, 
  d10:d30)

tidyCounts
```

<p>The above is what is often called a "<b>long</b>" data frame. Are all tidy data frames long? Not necessarily! That depends on the observational unit of your study.</p> 
<br>
<p>While it is more typical that untidy data frames are shaped in wide format, there are some instances when the opposite is the case. Take a moment to consider the following data frame of bird measurement data:</p>
<br>
<div class = "row">
```{r untidy HW2a, echo = FALSE, warning = FALSE}
kable(dfTooLong, "html") %>%
  kable_styling(
  bootstrap_options = c("striped", "hover"),
  full_width = FALSE,
  font_size = 16,
  position = "float_left"
  )
```
</div>

<p>In this instance the level of observation is the measurements associated with a given bird on a given date. Here, we see three measurements (mass, wing, and tail), have been recorded as three separate observations and multiple variables have been recorded in the same row. To fix this, we must convert from long to wide form. To do so, we use the `spread` function in `tidyr`. <i>Note that usage of the key-value pair is essentially the opposite of the usage within the gather function!</i>

```{r, eval = T, warning=FALSE}
spread(data = dfTooLong, 
  key = measurement, 
  value = value)
```

<p>Like all functions, the `tidyverse` functions above can be <b>nested</b> within the other. Nesting helps avoid assigning intermediate objects -- this can (occasionally) make your scripts easier to read, reduce naming conventions that can be difficult to remember or follow, and reduces the number of objects that need to be stored in your R environment. Let's take a look at non-nested and nested versions of our spread and gather functions using the point count observervations:</p>

```{r, eval = T, warning=FALSE}

# Non-nested functions:

wideFrame <- spread(longFrame, species, count, fill = 0)

longFrame2 <- gather(wideFrame, species, count, amro:grca)

# Nested functions:

longFrame2 <- gather(spread(longFrame, species, count, fill = 0),
  species, count, amro:grca)
```

<i>Be sure that you can successfully read the non-nested and nested versions of these functions!</i>

<p><i class= "fa fa-user-circle-o" style = "font-size: 100%;"></i> Notice that I added an argument above, `fill = 0`. Repeat the above without the `fill` argument. How do the two results differ? Have a look at the `spread` help file (`?spread`) for more information.</p>


<h3>Separating variables</h3>

<p>Oftentimes, multiple variables are stored in a single column of a data frame. This is easily dealt with using the `separate` function in tidyr. The dataset `birdCounts` is located in your global environment. These data are a subset of point counts taken throughout greater Washington D.C. The first few rows of this data frame are:</p>
<br>
<div class = "row">
```{r, eval = T, echo=F, warning=FALSE}
kable(head(birdCounts, 5), "html") %>%
  kable_styling(
  bootstrap_options = c("striped", "hover"),
  full_width = FALSE,
  font_size = 16,
  position = "float_left"
  )
```
</div>
<br>

<p>Take a moment to see how the data are structured:</p>

```{r eval=F}
birdCounts
levels(birdCounts$site)
```

The site column represents up to three numbered subsamples located within sites labelled from "a" to "o". We'll use `separate` to split this into two columns, "site" and "subsite".

```{r eval=F}
separate(birdCounts, site, into = c('site','subsite'), sep = '_')
```

That's pretty much all there is to "separate", pretty easy. For the sake of brevity, we'll leave tidying data behind for now. I strongly suggest reading Wickham's [Tidy Data](http://www.jstatsoft.org/v59/i10/paper) (2014) paper for further information on this powerful package.

----

> <b>Exercise 1</b>    
> The dataset "birdCounts" is located in your global environment. Using these data:
>
> 1. Convert birdCounts to a wide format dataset, setting NA values to 0. Assign the name "wideBirds" to this data frame.
>
> 2. Convert wideBirds to a tidy long format dataset. Assign the name "longBirds" to this data frame. _How do the birdCounts and longBirds data frames differ?_
>
> 3. Complete steps one and two using <b>nested</b> functions.

----

## dplyr

<b>dplyr</b> makes data manipulation simple by using just a few basic functions that satisfy most data manipulation tasks. It is considerably faster than most other data manipulation, which can be quite important when analyzing big data.

* <b>filter</b>: Remove rows that do not match a certain criteria

* <b>select</b>: Remove or maintain columns in a data set

* <b>arrange</b>: Reorder rows

* <b>mutate</b>: Create new variables

* <b>summarize</b>: Calculate a summary statistic -- this is most useful (or, perhaps, only useful) in combination with the function `group_by`.

### Subset data by observations

In our Introduction to R lesson, we subset the bird count rows using indexing. For example to view the counts of just foliage foraging species we enter:

```{r eval = F}
birdCounts[birdCounts$foraging == 'foliage',]
```

The `filter` fuction in `dplyr` works similarly, but the script is more concise:

```{r eval = F}
filter(birdCounts, foraging == 'foliage')
```

Note that the left side of the argument above is the data frame we are subsetting and the right hand of the argument is the logical condition. Because we have already specified the data frame from which we are filtering, it is not necessary to provide the name of the data frame within the logical condition. The advantage of this becomes readily apparent when we are filtering based on multiple conditions. Consider we would like to subset our birdCounts frame to foliage foraging species with an omnivorous diet. Let's compare the indexing and `dplyr` solution.

```{r eval = F}

birdCounts[birdCounts$foraging == 'foliage' & birdCounts$diet == 'omnivore',]

filter(birdCounts, foraging == 'foliage' & diet == 'omnivore')

```

And the advantage builds as we increase the number of selection criteria:


```{r eval = F}

birdCounts[birdCounts$foraging == 'foliage' & birdCounts$diet == 'omnivore' & birdCounts$count > 1,]

filter(birdCounts, foraging == 'foliage' & diet == 'omnivore' & count > 1)

```

----

> <img style="PADDING-LEFT:45px; PADDING-TOP: 0px; PADDING-BOTTOM: 5px" align = "right" src="http://www.allaboutbirds.org/guide/PHOTO/LARGE/carolina_chickadee_4.jpg" height="225px" width = "225px" title="Michael Drummond">
> <b>Exercise 2</b>    
Subset the birdCounts data frame to observations of Carolina Chickadee (_Poecile carolinensis_) in which two or more individuals were observed using:
>
> 1. Indexing
>    
> 2. dplyr's `filter` command  
    
----
    
### Subset data by columns

In our Introduction to R lesson we learned how to select columns from a data frame using indexing. We can select columns based on their position within the data frame or by name:

```{r eval = F}

# By position: 

birdCounts[,3:4]

# By name:

birdCounts[, c('count', 'foraging')]

```

We can use the `select` function in `dplyr` to select columns as well:

```{r eval = F}

# By position: 

select(birdCounts, 3:4)

# By name:

select(birdCounts, count, foraging)
```

The `select` function is more flexible than indexing, in that column names can be used in place of numbers to select a range of columns:

```{r eval = F}
select(birdCounts, count:diet)

```

To remove a column, you would use a minus sign:

```{r eval = F}
select(birdCounts, -site)

```

<h2>Arrange data in ascending or descending order</h2>

`dplyr` contains a handy function, `arrange` to sort data frames in ascending (low-to-high) or descending (high-to-low) order.
For example, if you wanted to arrange the birdCounts data frame by count:

```{r eval = F}

# Ascending:

arrange(birdCounts, count)

# Descending:

arrange(birdCounts, desc(count))

```

`arrange` also works with characters and factors to arrange alphabetically:

```{r, eval = F}
arrange(birdCounts, species)
```


## The **pipe** operator

One of the greatest recent advancements in the world of R is the implementation of the **pipe operator**. A pipe operator allows you to set the output of one process as the input of another -- thus sequences of calculations are chained together without having to define intermediate steps as R objects (_Note: Piping is sometimes called chaining_). Piping was first implemented in R by ecologist and R guru Ben Bolker, in an answer to a question on stackoverflow. <img style="PADDING-LEFT:25px; PADDING-TOP: 5px" align = "right" src="https://upload.wikimedia.org/wikipedia/en/b/b9/MagrittePipe.jpg" height="300px" width = "300"/>  Hadley Wickham introduced his version of piping to his `dplyr` package in 2013 while concurrently Stefan Milton Bache developed a more flexible version for his package `magrittr` (named after Magritte's painting, _The Treachery of Images_). In 2014, Wickham and Bache teamed up and Bache's pipe was incorporated into `dplyr`.

Piping makes scripts more readable (see a pattern here?) and saves system memory by reducing the amount of data stored in R's Global Environment. Take a moment to look at your Global Environment (upper right-hand pane in R Studio). You've got lots of objects in there. Likewise, if you didn't do a great job naming your R objects, you may have a hard time remembering what each was. An alternative, nested functions, are problematically complicated to read. Piping avoids the necessity to assign intermediate objects and makes scripts legible by conducting analyses in sequence. Let's look at our `dplyr` summarizing operation above.

```{r, eval = F}
birdCountsForaging <- group_by(birdCounts, foraging)

summarize(birdCountsForaging, N = sum(count))
``` 

To nest these functions, we would write:

```{r, eval = F}
summarize(group_by(birdCounts, foraging), N = sum(count))
``` 

To pipe this operation, we use the `%>%` symbol to separate arguments. Our first argument is the name of the data frame we are evaluating. This allowed us to omit the name of the data frame in the functions that follow. For each subsequent step, functions are carried out on the data frame reduced by the step to the left (or up).

```{r, eval = F}
birdCounts %>% 
  group_by(foraging) %>%
  summarize(N = sum(count))
```

The piping symbol, `%>%`, represents the word "then". We would read the above as "use the data frame bird counts _then_ group by foraging _then_ calculate the sum for each group".

Notice that I used multiple indented lines of code. For maximal readibility, it is **highly recommended** that any multi-step operation should be formatted as such (this is considered **best management practices** for programmers across languages).

Take a moment to think of the difference between the piped and nested-function versions of the operation above. You'll notice that the piped version reads from left-to-right (or up-to-down). The dataset becomes progressively smaller with each step to the right (or down). Conversely, the summarize function reads from the inside out. In the nested functions, `group_by` is actually the first step in the sequence, but it is instead nested in the middle of the `summarize` function! This is what makes nested functions, especially if data analyses are complex, so difficult to read.

----

> **Exercise 7**    
> Give another try to Exercises 1-6 above, this time using **piping** to complete each exercise in one step.
>

----

_**A final note**: You should consider **every** script you write to be a **communication** between you and your future self and yourself and fellow scientists. Make sure your scripts communicate clearly -- future you and your fellow scientists will appreciate it greatly!_

----

